{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "robust-printer",
   "metadata": {},
   "outputs": [],
   "source": [
    "from music21 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "military-bankruptcy",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining function to read MIDI files\n",
    "def read_midi(file):\n",
    "    \n",
    "    print(\"Loading Music File:\",file)\n",
    "    \n",
    "    notes=[]\n",
    "    notes_to_parse = None\n",
    "    \n",
    "    #parsing a midi file\n",
    "    midi = converter.parse(file)\n",
    "  \n",
    "    #grouping based on different instruments\n",
    "    s2 = instrument.partitionByInstrument(midi)\n",
    "\n",
    "    #Looping over all the instruments\n",
    "    for part in s2.parts:\n",
    "    \n",
    "        #select elements of only piano\n",
    "        if 'Piano' in str(part): \n",
    "        \n",
    "            notes_to_parse = part.recurse() \n",
    "      \n",
    "            #finding whether a particular element is note or a chord\n",
    "            for element in notes_to_parse:\n",
    "                \n",
    "                #note\n",
    "                if isinstance(element, note.Note):\n",
    "                    notes.append(str(element.pitch))\n",
    "                \n",
    "                #chord\n",
    "                elif isinstance(element, chord.Chord):\n",
    "                    notes.append('.'.join(str(n) for n in element.normalOrder))\n",
    "\n",
    "    return np.array(notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "immune-polymer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Music File: data/schumm-1.mid\n",
      "Loading Music File: data/schub_d960_4.mid\n",
      "Loading Music File: data/schub_d760_2.mid\n",
      "Loading Music File: data/schubert_D935_1.mid\n",
      "Loading Music File: data/schubert_D935_2.mid\n",
      "Loading Music File: data/schub_d760_4.mid\n",
      "Loading Music File: data/schuim-2.mid\n",
      "Loading Music File: data/schub_d960_3.mid\n",
      "Loading Music File: data/schumm-4.mid\n",
      "Loading Music File: data/schu_143_1.mid\n",
      "Loading Music File: data/schumm-6.mid\n",
      "Loading Music File: data/schub_d760_3.mid\n",
      "Loading Music File: data/schu_143_2.mid\n",
      "Loading Music File: data/schumm-5.mid\n",
      "Loading Music File: data/schuim-4.mid\n",
      "Loading Music File: data/schubert_D935_4.mid\n",
      "Loading Music File: data/schuim-3.mid\n",
      "Loading Music File: data/schubert_D850_1.mid\n",
      "Loading Music File: data/schubert_D935_3.mid\n",
      "Loading Music File: data/schuim-1.mid\n",
      "Loading Music File: data/schubert_D850_2.mid\n",
      "Loading Music File: data/schubert_D850_3.mid\n",
      "Loading Music File: data/schu_143_3.mid\n",
      "Loading Music File: data/schub_d960_2.mid\n",
      "Loading Music File: data/schubert_D850_4.mid\n",
      "Loading Music File: data/schub_d960_1.mid\n",
      "Loading Music File: data/schumm-2.mid\n",
      "Loading Music File: data/schumm-3.mid\n",
      "Loading Music File: data/schub_d760_1.mid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-16-1804b1d512ae>:14: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  notes_array = np.array([read_midi(path+i) for i in files])\n"
     ]
    }
   ],
   "source": [
    "#for listing down the file names\n",
    "import os\n",
    "\n",
    "#Array Processing\n",
    "import numpy as np\n",
    "\n",
    "#specify the path\n",
    "path='data/'\n",
    "\n",
    "#read all the filenames\n",
    "files=[i for i in os.listdir(path) if i.endswith(\".mid\")]\n",
    "\n",
    "#reading each midi file\n",
    "notes_array = np.array([read_midi(path+i) for i in files])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "naughty-passing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "308\n"
     ]
    }
   ],
   "source": [
    "#converting 2D array into 1D array\n",
    "notes_ = [element for note_ in notes_array for element in note_]\n",
    "\n",
    "#No. of unique notes\n",
    "unique_notes = list(set(notes_))\n",
    "print(len(unique_notes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "married-motorcycle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([186.,  46.,  27.,  10.,   4.,   6.,   6.,  12.,   8.,   3.]),\n",
       " array([1.0000e+00, 1.7290e+02, 3.4480e+02, 5.1670e+02, 6.8860e+02,\n",
       "        8.6050e+02, 1.0324e+03, 1.2043e+03, 1.3762e+03, 1.5481e+03,\n",
       "        1.7200e+03]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 302,
       "width": 324
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#importing library\n",
    "from collections import Counter\n",
    "\n",
    "#computing frequency of each note\n",
    "freq = dict(Counter(notes_))\n",
    "\n",
    "#library for visualiation\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#consider only the frequencies\n",
    "no=[count for _,count in freq.items()]\n",
    "\n",
    "#set the figure size\n",
    "plt.figure(figsize=(5,5))\n",
    "\n",
    "#plot\n",
    "plt.hist(no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "lyric-assurance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "173\n"
     ]
    }
   ],
   "source": [
    "frequent_notes = [note_ for note_, count in freq.items() if count>=50]\n",
    "print(len(frequent_notes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "textile-generator",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-20-2fa7923ce1b3>:10: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  new_music = np.array(new_music)\n"
     ]
    }
   ],
   "source": [
    "new_music=[]\n",
    "\n",
    "for notes in notes_array:\n",
    "    temp=[]\n",
    "    for note_ in notes:\n",
    "        if note_ in frequent_notes:\n",
    "            temp.append(note_)            \n",
    "    new_music.append(temp)\n",
    "    \n",
    "new_music = np.array(new_music)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "second-therapist",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_of_timesteps = 32\n",
    "x = []\n",
    "y = []\n",
    "\n",
    "for note_ in new_music:\n",
    "    for i in range(0, len(note_) - no_of_timesteps, 1):\n",
    "        \n",
    "        #preparing input and output sequences\n",
    "        input_ = note_[i:i + no_of_timesteps]\n",
    "        output = note_[i + no_of_timesteps]\n",
    "        \n",
    "        x.append(input_)\n",
    "        y.append(output)\n",
    "        \n",
    "x=np.array(x)\n",
    "y=np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "quality-museum",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_x = list(set(x.ravel()))\n",
    "x_note_to_int = dict((note_, number) for number, note_ in enumerate(unique_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "assigned-saturn",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preparing input sequences\n",
    "x_seq=[]\n",
    "for i in x:\n",
    "    temp=[]\n",
    "    for j in i:\n",
    "        #assigning unique integer to every note\n",
    "        temp.append(x_note_to_int[j])\n",
    "    x_seq.append(temp)\n",
    "    \n",
    "x_seq = np.array(x_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "civic-webster",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_y = list(set(y))\n",
    "y_note_to_int = dict((note_, number) for number, note_ in enumerate(unique_y)) \n",
    "y_seq=np.array([y_note_to_int[i] for i in y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "mobile-barcelona",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_tr, x_val, y_tr, y_val = train_test_split(x_seq,y_seq,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "criminal-heavy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm():\n",
    "  model = Sequential()\n",
    "  model.add(LSTM(128,return_sequences=True))\n",
    "  model.add(LSTM(128))\n",
    "  model.add(Dense(256))\n",
    "  model.add(Activation('relu'))\n",
    "  model.add(Dense(n_vocab))\n",
    "  model.add(Activation('softmax'))\n",
    "  model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "automated-belief",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 32, 100)           17300     \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 32, 64)            19264     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32, 64)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 10, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 10, 128)           24704     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 10, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 3, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 3, 256)            98560     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 3, 256)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 1, 256)            0         \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 173)               44461     \n",
      "=================================================================\n",
      "Total params: 270,081\n",
      "Trainable params: 270,081\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "from keras.callbacks import *\n",
    "import keras.backend as K\n",
    "\n",
    "K.clear_session()\n",
    "model = Sequential()\n",
    "    \n",
    "#embedding layer\n",
    "model.add(Embedding(len(unique_x), 100, input_length=32,trainable=True)) \n",
    "\n",
    "model.add(Conv1D(64,3, padding='causal',activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(MaxPool1D(2))\n",
    "    \n",
    "model.add(Conv1D(128,3,activation='relu',dilation_rate=2,padding='causal'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(MaxPool1D(2))\n",
    "\n",
    "model.add(Conv1D(256,3,activation='relu',dilation_rate=4,padding='causal'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(MaxPool1D(2))\n",
    "          \n",
    "#model.add(Conv1D(256,5,activation='relu'))    \n",
    "model.add(GlobalMaxPool1D())\n",
    "    \n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(len(unique_y), activation='softmax'))\n",
    "    \n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "governmental-listing",
   "metadata": {},
   "outputs": [],
   "source": [
    "mc=ModelCheckpoint('best_model.h5', monitor='val_loss', mode='min', save_best_only=True,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "twelve-ghost",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "503/503 [==============================] - 15s 29ms/step - loss: 2.7506 - val_loss: 3.0713\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 3.06366\n",
      "Epoch 2/150\n",
      "503/503 [==============================] - 16s 32ms/step - loss: 2.7408 - val_loss: 3.0599\n",
      "\n",
      "Epoch 00002: val_loss improved from 3.06366 to 3.05989, saving model to best_model_500.h5\n",
      "Epoch 3/150\n",
      "503/503 [==============================] - 14s 28ms/step - loss: 2.7455 - val_loss: 3.0546\n",
      "\n",
      "Epoch 00003: val_loss improved from 3.05989 to 3.05461, saving model to best_model_500.h5\n",
      "Epoch 4/150\n",
      "503/503 [==============================] - 14s 28ms/step - loss: 2.7387 - val_loss: 3.0516\n",
      "\n",
      "Epoch 00004: val_loss improved from 3.05461 to 3.05156, saving model to best_model_500.h5\n",
      "Epoch 5/150\n",
      "503/503 [==============================] - 16s 32ms/step - loss: 2.7353 - val_loss: 3.0522\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 3.05156\n",
      "Epoch 6/150\n",
      "503/503 [==============================] - 14s 28ms/step - loss: 2.7249 - val_loss: 3.0476\n",
      "\n",
      "Epoch 00006: val_loss improved from 3.05156 to 3.04761, saving model to best_model_500.h5\n",
      "Epoch 7/150\n",
      "503/503 [==============================] - 14s 28ms/step - loss: 2.7227 - val_loss: 3.0320\n",
      "\n",
      "Epoch 00007: val_loss improved from 3.04761 to 3.03205, saving model to best_model_500.h5\n",
      "Epoch 8/150\n",
      "503/503 [==============================] - 15s 29ms/step - loss: 2.7176 - val_loss: 3.0319\n",
      "\n",
      "Epoch 00008: val_loss improved from 3.03205 to 3.03187, saving model to best_model_500.h5\n",
      "Epoch 9/150\n",
      "503/503 [==============================] - 17s 34ms/step - loss: 2.7123 - val_loss: 3.0301\n",
      "\n",
      "Epoch 00009: val_loss improved from 3.03187 to 3.03012, saving model to best_model_500.h5\n",
      "Epoch 10/150\n",
      "503/503 [==============================] - 12s 25ms/step - loss: 2.7185 - val_loss: 3.0369\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 3.03012\n",
      "Epoch 11/150\n",
      "503/503 [==============================] - 12s 25ms/step - loss: 2.7051 - val_loss: 3.0320\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 3.03012\n",
      "Epoch 12/150\n",
      "503/503 [==============================] - 15s 31ms/step - loss: 2.6944 - val_loss: 3.0304\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 3.03012\n",
      "Epoch 13/150\n",
      "503/503 [==============================] - 17s 33ms/step - loss: 2.7009 - val_loss: 3.0256\n",
      "\n",
      "Epoch 00013: val_loss improved from 3.03012 to 3.02561, saving model to best_model_500.h5\n",
      "Epoch 14/150\n",
      "503/503 [==============================] - 15s 29ms/step - loss: 2.6959 - val_loss: 3.0289\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 3.02561\n",
      "Epoch 15/150\n",
      "503/503 [==============================] - 13s 27ms/step - loss: 2.6993 - val_loss: 3.0305\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 3.02561\n",
      "Epoch 16/150\n",
      "503/503 [==============================] - 14s 27ms/step - loss: 2.6929 - val_loss: 3.0187\n",
      "\n",
      "Epoch 00016: val_loss improved from 3.02561 to 3.01869, saving model to best_model_500.h5\n",
      "Epoch 17/150\n",
      "503/503 [==============================] - 13s 26ms/step - loss: 2.6833 - val_loss: 3.0194\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 3.01869\n",
      "Epoch 18/150\n",
      "503/503 [==============================] - 16s 33ms/step - loss: 2.6868 - val_loss: 3.0220\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 3.01869\n",
      "Epoch 19/150\n",
      "503/503 [==============================] - 15s 30ms/step - loss: 2.6837 - val_loss: 3.0198\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 3.01869\n",
      "Epoch 20/150\n",
      "503/503 [==============================] - 13s 26ms/step - loss: 2.6743 - val_loss: 3.0137\n",
      "\n",
      "Epoch 00020: val_loss improved from 3.01869 to 3.01374, saving model to best_model_500.h5\n",
      "Epoch 21/150\n",
      "503/503 [==============================] - 13s 26ms/step - loss: 2.6770 - val_loss: 3.0048\n",
      "\n",
      "Epoch 00021: val_loss improved from 3.01374 to 3.00478, saving model to best_model_500.h5\n",
      "Epoch 22/150\n",
      "503/503 [==============================] - 16s 32ms/step - loss: 2.6688 - val_loss: 3.0073\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 3.00478\n",
      "Epoch 23/150\n",
      "503/503 [==============================] - 14s 28ms/step - loss: 2.6707 - val_loss: 3.0091\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 3.00478\n",
      "Epoch 24/150\n",
      "503/503 [==============================] - 13s 26ms/step - loss: 2.6681 - val_loss: 3.0100\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 3.00478\n",
      "Epoch 25/150\n",
      "503/503 [==============================] - 15s 30ms/step - loss: 2.6581 - val_loss: 3.0023\n",
      "\n",
      "Epoch 00025: val_loss improved from 3.00478 to 3.00228, saving model to best_model_500.h5\n",
      "Epoch 26/150\n",
      "453/503 [==========================>...] - ETA: 1s - loss: 2.6631"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-23bf6f2dbcfd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_tr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_tr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2942\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    553\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(np.array(x_tr),np.array(y_tr),batch_size=128,epochs=50, validation_data=(np.array(x_val),np.array(y_val)),verbose=1, callbacks=[mc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "improving-memorabilia",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading best model\n",
    "from keras.models import load_model\n",
    "model = load_model('best_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "superb-popularity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[109, 66, 4, 54, 118, 118, 118, 118, 118, 4, 118, 118, 4, 4, 89, 89, 89, 167, 60, 167, 60, 60, 60, 60, 60, 60, 115, 115, 115, 115, 115, 115, 115, 68, 115, 68, 115, 115, 68, 68, 115, 115, 115, 130, 155, 9, 86, 9, 127, 9, 167, 166, 167, 166, 167, 166, 127, 127, 167, 127, 127, 127, 9, 167, 9, 82, 9, 9, 61, 166, 166, 166, 166, 166, 166, 120, 166, 166, 120, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "ind = np.random.randint(0,len(x_val)-1)\n",
    "\n",
    "random_music = x_val[ind]\n",
    "\n",
    "predictions=[]\n",
    "for i in range(100):\n",
    "\n",
    "    random_music = random_music.reshape(1,no_of_timesteps)\n",
    "\n",
    "    prob  = model.predict(random_music)[0]\n",
    "    y_pred= np.argmax(prob,axis=0)\n",
    "    predictions.append(y_pred)\n",
    "\n",
    "    random_music = np.insert(random_music[0],len(random_music[0]),y_pred)\n",
    "    random_music = random_music[1:]\n",
    "    \n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "convenient-internet",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_int_to_note = dict((number, note_) for number, note_ in enumerate(unique_x)) \n",
    "predicted_notes = [x_int_to_note[i] for i in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "accepting-timer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_midi(prediction_output):\n",
    "   \n",
    "    offset = 0\n",
    "    output_notes = []\n",
    "\n",
    "    # create note and chord objects based on the values generated by the model\n",
    "    for pattern in prediction_output:\n",
    "        \n",
    "        # pattern is a chord\n",
    "        if ('.' in pattern) or pattern.isdigit():\n",
    "            notes_in_chord = pattern.split('.')\n",
    "            notes = []\n",
    "            for current_note in notes_in_chord:\n",
    "                \n",
    "                cn=int(current_note)\n",
    "                new_note = note.Note(cn)\n",
    "                new_note.storedInstrument = instrument.Piano()\n",
    "                notes.append(new_note)\n",
    "                \n",
    "            new_chord = chord.Chord(notes)\n",
    "            new_chord.offset = offset\n",
    "            output_notes.append(new_chord)\n",
    "            \n",
    "        # pattern is a note\n",
    "        else:\n",
    "            \n",
    "            new_note = note.Note(pattern)\n",
    "            new_note.offset = offset\n",
    "            new_note.storedInstrument = instrument.Piano()\n",
    "            output_notes.append(new_note)\n",
    "\n",
    "        # increase offset each iteration so that notes do not stack\n",
    "        offset += 1\n",
    "    midi_stream = stream.Stream(output_notes)\n",
    "    midi_stream.write('midi', fp='music3.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "aggregate-jamaica",
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_to_midi(predicted_notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "obvious-worship",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
